---
title: "ADS-502-Group-6-Final_Project"
output: html_document
date: "`r Sys.Date()`"
 markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ADS 502 Applied Data Mining Final Group Project

## Group 6

### Dip Raj Bista + Logan Van Dine + Ghassan Seba

*`This data mining project aims to assist a mobile phone company in estimating the price range of their products based on various features such as RAM, Internal Memory, etc. By analyzing historical sales data from different mobile phone companies, the project seeks to uncover relationships between multiple features and ‘selling price.’ The objective is to provide actionable insights enabling the company to price their mobile phones appropriately and become more competitive while utilizing a classification model.`*

### Import dataset and describe characteristics such as dimensions, data types, file types, missing data, and statistical description of data.

```{r}
# Load data files
mobileTrain <- read.csv("train.csv", header = TRUE)
```

```{r}
# Find training data set dimensions
dimenTrain <- dim(mobileTrain)
print(dimenTrain)
```

```{r}
# suppressMessages()
suppressMessages({
  
# Load conflicted package 
library(conflicted)
  
# Load the tidyverse package
library(tidyverse)

# Get the column names and data types
colnamesTrain <- colnames(mobileTrain)
dtypeTrain <- sapply(mobileTrain, class)

# Clean the output
colnamesTrain <- str_pad(colnamesTrain, 10, side = "left")
dtypeTrain <- str_pad(dtypeTrain, 10, side = "left")

# Combine the two into a single data frame
df <- tibble(
  colname = colnamesTrain,
  dtype = dtypeTrain
)

# Print the data frame
print(df)
})
```

```{r}
# Display summary statistics for the training data set
summaryTrain <- summary(mobileTrain)

print(summaryTrain)

```

```{r}
# Get the sum of missing values for each column
missingTrain <- colSums(is.na(mobileTrain))

# Column names
trainColumnNames <- names(missingTrain)

# Create a new data frame with column names and missing value counts
missingTrainTable <- data.frame(Column = trainColumnNames, MissingTrainCount = missingTrain)

# Print the tidy table to the console
cat(sprintf("%-15s %-15s\n", "Column Name", "NA Count"))
cat("---------------------------\n")
for (i in seq_along(missingTrainTable$Column)) {
  cat(sprintf("%-15s %-15d\n", missingTrainTable$Column[i], missingTrainTable$MissingTrainCount[i]))
}
```

## Data Description:

### Categorical Variables:

-   *`blue`*: Binary categorical variable indicating whether the mobile has Bluetooth (0 or 1).
-   *`dual_sim`*: Binary categorical variable indicating whether the mobile has dual SIM capability (0 or 1).
-   *`four_g`*: Binary categorical variable indicating whether the mobile supports 4G (0 or 1).
-   *`three_g`*: Binary categorical variable indicating whether the mobile supports 3G (0 or 1).
-   *`touch_screen`*: Binary categorical variable indicating whether the mobile has a touch screen (0 or 1).
-   *`wifi`*: Binary categorical variable indicating whether the mobile has Wi-Fi capability (0 or 1).
-   *`price_range`*: TARGET VARIABLE; Categorical variable representing the price range of the mobile. It has discrete values (0, 1, 2, 3).

### Integer Variables:

-   *`battery_power`*: Discrete integer variable representing the battery power of the mobile.
-   *`fc`*: Discrete integer variable representing the front camera megapixels of the mobile.
-   *`int_memory`*: Discrete integer variable representing the internal memory in GB of the mobile.
-   *`mobile_wt`*: Discrete integer variable representing the weight of the mobile.
-   *`n_cores`*: Discrete integer variable representing the number of cores of the mobile's processor.
-   *`pc`*: Discrete integer variable representing the primary camera megapixels of the mobile.
-   *`px_height`*: Discrete integer variable representing the pixel height of the mobile.
-   *`px_width`*: Discrete integer variable representing the pixel width of the mobile.
-   *`ram`*: Discrete integer variable representing the RAM of the mobile in MB.
-   *`sc_h`*: Discrete integer variable representing the screen height of the mobile.
-   *`sc_w`*: Discrete integer variable representing the screen width of the mobile.
-   *`talk_time`*: Discrete integer variable representing the talk time of the mobile in hours.
-   *`id`*: Discrete integer variable representing the unique ID of the mobile (present in the test dataset).

### Numeric Variables:

-   *`clock_speed`*: Continuous numeric variable representing the clock speed of the mobile's processor.
-   *`m_dep`*: Continuous numeric variable representing the mobile depth.

### Data Distribution

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Define the number of rows and columns for the subplot matrix
num_rows <- 2
num_cols <- 7

# Select only the continuous and discrete integer columns from the mobileTrain dataset
selected_cols <- mobileTrain[, c("battery_power", "fc", "int_memory", "mobile_wt", 
                                 "n_cores", "pc", "px_height", "px_width", "ram", 
                                 "sc_h", "sc_w", "talk_time", "clock_speed", "m_dep")]

# Convert the selected data frame to long format
mobileTrain_long <- tidyr::pivot_longer(selected_cols, 
                                       cols = everything(),
                                       names_to = "name", values_to = "value")

# Convert the 'name' column to a factor or character variable
mobileTrain_long$name <- as.factor(mobileTrain_long$name)

# Create the boxplot using ggplot2 with mean markers
trainingPlots <- ggplot(mobileTrain_long, aes(x = name, y = value)) +
  geom_boxplot() +
  stat_boxplot(geom = "errorbar", width = 0.2, position = position_dodge(width = 0.75)) +
  stat_summary(fun = mean, geom = "point", shape = 5, size = 3, color = "red",
               position = position_dodge(width = 0.75)) +
  facet_wrap(~name, scales = "free_x", ncol = num_cols) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(trainingPlots)
```

```{r}
# Comparison of Integer and Continuous Variables PRE Normalization

# Integer
hist(mobileTrain$int_memory, main="Internal Memory Megapixels Frequency of Mobile Phones", xlab="Internal Memory", col="lightblue")

hist(mobileTrain$ram, main="RAM Frequency of Mobile Phones", xlab="RAM", col="darkmagenta")

#Continuous
hist(mobileTrain$clock_speed, main="Clock Speed Frequency of Mobile Phones", xlab="Clock Speed", col="lightpink")
```

The box-and-whisker plots above prove that normalization is needed for the training data set. Normalization will allow for statistical analysis of all variables in relation to the price range variable on the same scale. Normalization will also allow a better visualization of outliers in the data set and the distribution of variables to be used.

The histograms also prove that normalization is necessary. For example, in a variable such as internal memory, the box-and-whisker plots gave no valuable information about the distribution.

### Normalize the training Data Set for proper analysis

# Perform Min-Max scaling

```{r}
# Load necessary libraries
library(dplyr)

# Min-Max scaling
min_max_norm <- function(x) {(x - min(x)) / (max(x) - min(x))}

#Apply normalization to necessacry columns (all columns - target)
normalized_mobileTrain <- as.data.frame(lapply(mobileTrain[1:20], min_max_norm))

#Add target variable (price_range) back
normalized_mobileTrain$price_range <- mobileTrain$price_range

#Validate normalization and target variable
head(normalized_mobileTrain)
```

### Plot normalized continuous variables in training data set

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Define the number of rows and columns for the subplot matrix
num_rows <- 2
num_cols <- 7

# Select only the continuous and discrete integer columns from the mobileTrain dataset
selected_cols <- normalized_mobileTrain[, c("battery_power", "fc", "int_memory", "mobile_wt", 
                                 "n_cores", "pc", "px_height", "px_width", "ram", 
                                 "sc_h", "sc_w", "talk_time", "clock_speed", "m_dep")]

# Convert the selected data frame to long format
mobileTrain_long <- tidyr::pivot_longer(selected_cols, 
                                       cols = everything(),
                                       names_to = "name", values_to = "value")

# Convert the 'name' column to a factor or character variable
mobileTrain_long$name <- as.factor(mobileTrain_long$name)

# Create the boxplot using ggplot2 with mean markers
trainingPlots <- ggplot(mobileTrain_long, aes(x = name, y = value)) +
  geom_boxplot() +
  stat_boxplot(geom = "errorbar", width = 0.2, position = position_dodge(width = 0.75)) +
  stat_summary(fun = mean, geom = "point", shape = 5, size = 3, color = "red",
               position = position_dodge(width = 0.75)) +
  facet_wrap(~name, scales = "free_x", ncol = num_cols) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(trainingPlots)
```

After normalization, all numeric variables are on a scale 0 to 1. This action allows us to statistically analyze the distribution of variables in comparison to one another. For example, it is now known that battery_power, int_memory, mobile_wt, pc, px_width, ram, sc_h, and talk_time are normally distributed. Normalization also provides insight to which variables contain outliers in the training data set, fc and px_height.

Before correlations between variables can be determined, the outliers need to be identified and potentially removed.

### Identify outliers in the continuous variables via z-score

```{r}
# Function to calculate z-scores for a vector
calculate_z_scores <- function(x) {
  (x - mean(x)) / sd(x)
}

# Calculate z-scores for each column
z_scores <- mobileTrain_long %>%
  group_by(name) %>%
  mutate(z_score = calculate_z_scores(value))

# Set the z-score threshold for outlier detection
z_score_threshold <- 3

# Identify outliers based on z-scores
outliers <- z_scores %>%
  dplyr::filter(abs(z_score) > z_score_threshold)

# Print the outliers
print(outliers)
```

A common threshold for z-scores is 3 (positive or negative). With this knowledge, a threshold of 3 has been applied to the normalized numeric variable z-scores. After applying the threshold, we find that there are 12 records in the fc variable that are determined as outliers. As these records only account for 0.6% of the data, they will be removed in the next step.

### Remove Outliers from data set

```{r}
# Load necessary libraries
library(dplyr)

# Calculate z-scores for each column
z_scores <- apply(normalized_mobileTrain, 2, function(x) abs((x - mean(x)) / sd(x)))

# Find rows with z-scores greater than 3 in any column
outliers <- rowSums(z_scores > 3) > 0

# Filter out the outliers from the dataset
filtered_mobileTrain <- normalized_mobileTrain[!outliers, ]

# get dimensions of the filtered dataset
dim(filtered_mobileTrain)

```

### Verify Impact of Outliers Removal

```{r}
# Load necessary libraries
library(dplyr)

# Calculate z-scores for each column
z_scores <- apply(normalized_mobileTrain, 2, function(x) abs((x - mean(x)) / sd(x)))

# Find rows with z-scores greater than 3 in any column
outliers <- rowSums(z_scores > 3) > 0

# Filter out the outliers from the dataset
filtered_mobileTrain <- normalized_mobileTrain[!outliers, ]

# Print summary statistics of the original dataset
print(summary(normalized_mobileTrain))

# Print summary statistics of the filtered dataset
print(summary(filtered_mobileTrain))
```

With only 0.6% of the data being removed, there is not a large difference in distribution and summary statistics of variables after removal of the fc outliers.

### Plot filtered data set to check for outliers

```{r}
library(ggplot2)

# Define the number of rows and columns for the subplot matrix
num_rows <- 2
num_cols <- 7

numeric_vars <- c("battery_power","clock_speed", "fc", "int_memory", "m_dep",	"mobile_wt", "n_cores","pc", "px_height",	"px_width", "ram", "sc_h", "sc_w", "talk_time")

# Select only the numeric variables from the filtered_mobileTrain dataset
selected_cols <- filtered_mobileTrain %>%
  select(all_of(numeric_vars))

# Convert the column names to a factor or character variable
selected_cols <- selected_cols %>%
  gather(name, value)

# Create the boxplot using ggplot2 with mean markers
trainingPlotsFiltered <- ggplot(selected_cols, aes(x = name, y = value)) +
  geom_boxplot() +
  stat_boxplot(geom = "errorbar", width = 0.2, position = position_dodge(width = 0.75)) +
  stat_summary(fun = mean, geom = "point", shape = 5, size = 3, color = "red",
               position = position_dodge(width = 0.75)) +
  facet_wrap(~name, scales = "free_x", ncol = num_cols) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(trainingPlotsFiltered)

```

### Distribution of Binary Variables

```{r}
# Load necessary libraries
library(ggplot2)

# Select only the binary columns from the normalized_mobileTrain dataset
binary_cols <- filtered_mobileTrain[, c("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi")]

# Get the table of counts for each binary variable
binary_counts <- lapply(binary_cols, table)

# Combine the counts into a single data frame
binary_df <- do.call(rbind, lapply(names(binary_counts), function(var_name) {
  data.frame(Variable = rep(var_name, 2),
             Value = as.factor(c("0", "1")),
             Count = as.numeric(binary_counts[[var_name]]))
}))

# Create the heatmap using ggplot2
heatmap_plot <- ggplot(binary_df, aes(x = Variable, y = Value, fill = Count)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(heatmap_plot)
```

### Correlation Matrix of Numeric Variables

```{r}
# suppressMessages()
suppressMessages({
# Library
library(Hmisc)

# Correlation matrix of all Numeric Variables

#Data Frame of Numeric Variables

corr_train_data <- filtered_mobileTrain %>%
  select(battery_power, fc, int_memory, mobile_wt, n_cores, pc, px_height, px_width, ram, sc_h, sc_w, talk_time, clock_speed, m_dep)

# Correlation Matrix followed by p-value matrix

#corr_train_data.cor = cor(corr_train_data)
#corr_train_data.cor #commented out to avoid redundancy

p_correlation = rcorr(as.matrix(corr_train_data))
p_correlation
})
```

### Correlation Heatmap for Numeric Variables

```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)  # for melt function

# Define the numeric and categorical variables
numeric_vars <- c("battery_power","clock_speed", "fc", "int_memory", "m_dep",	"mobile_wt", "n_cores","pc", "px_height", "px_width", "ram", "sc_h", "sc_w", "talk_time")
categorical_vars <- c("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi", "price_range")

# Convert categorical variables to factors for the filtered dataset
filtered_factored_mobileTrain <- filtered_mobileTrain %>%
  mutate_at(vars(all_of(categorical_vars)), as.factor)

# Calculate the correlation matrix for numeric variables
cor_matrix <- cor(filtered_factored_mobileTrain[, numeric_vars])

# Create a heatmap of the correlation matrix
heatmap_data <- as.data.frame(as.table(cor_matrix))
colnames(heatmap_data) <- c("Variable_1", "Variable_2", "Correlation")  # Replace spaces with underscores

# Create the heatmap with correlation values as labels
ggplot(heatmap_data, aes(x = Variable_1, y = Variable_2, fill = Correlation)) +
  geom_tile() +
  geom_text(aes(label = round(Correlation, 2)), vjust = 0.5, size = 3) +  # Add correlation values as labels
  scale_fill_gradient2(low = "white", mid = "blue", high = "yellow", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Correlation Heatmap for Numeric Variables")
```

The correlation matrix and heatmap of coefficients do not prove any drastically strong relationships between variables. In terms of multicollinearity, this is a positive for model creation as variables are not too strongly related to predict the target variable. However, in terms of feature selection, there are no obvious selections to be made. A p-value matrix was created to indulge in further statistical analysis. Features will partially be selected based on the statistical significance of the relationship to other variables; not overbearingly strong but not non-existent.

### Correlation with Target Variable

*`Higher absolute correlation values indicate potentially important features.`*

```{r}
# Map factor levels to numeric values for price_range
filtered_factored_mobileTrain$price_numeric <- as.numeric(filtered_factored_mobileTrain$price_range) - 1

# Calculate correlations with the new numeric version of price_range
cor_with_target <- sapply(numeric_vars, function(var) cor(filtered_factored_mobileTrain[[var]], filtered_factored_mobileTrain$price_numeric))

# Print correlation values with the target variable neatly
cat("Correlation with the target variable (price_range):\n")
for (i in 1:length(numeric_vars)) {
  cat(numeric_vars[i], ": ", cor_with_target[i], "\n")}
```

### Visualize the correlations between the numeric variables and the target variable "price_range" using a bar plot

```{r}
# Convert factor levels of price_range to numeric values
filtered_mobileTrain$price_numeric <- as.numeric(filtered_mobileTrain$price_range) - 1

# Calculate the correlation with the target variable
cor_with_target <- sapply(numeric_vars, function(var) cor(filtered_mobileTrain[[var]], filtered_mobileTrain$price_numeric))

# Remove the temporary price_numeric variable
filtered_factored_mobileTrain$price_numeric <- NULL

# Create a data frame for plotting
cor_df <- data.frame(Variable = numeric_vars, Correlation = cor_with_target)

# Plot correlation values with the target variable using a bar plot
library(ggplot2)

ggplot(cor_df, aes(x = reorder(Variable, -Correlation), y = Correlation)) +
  geom_bar(stat = "identity", fill = "dodgerblue") +
  coord_flip() +
  labs(title = "Correlation with the target variable (price_range)",
       x = "Numeric Variable",
       y = "Correlation") +
  theme_minimal()
```

### Numeric Variable Covariance Analysis to identify strongly correlated features

```{r}
# Load necessary libraries
library(dplyr)

# Define the numeric and categorical variables
numeric_vars <- c("battery_power", "clock_speed", "fc", "int_memory", "m_dep", "mobile_wt", "n_cores", "pc", "px_height", "px_width", "ram", "sc_h", "sc_w", "talk_time")
categorical_vars <- c("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi", "price_range")

# Convert categorical variables to factors for the filtered dataset
filtered_mobileTrain <- filtered_mobileTrain %>%
  mutate_at(vars(all_of(categorical_vars)), as.factor)

# Calculate the covariance matrix for numeric variables in the filtered dataset
cov_matrix_filtered <- cov(filtered_mobileTrain[, numeric_vars])

# Print covariance matrix with variable names for the filtered dataset
cat("Covariance Matrix for Numeric Variables:\n")
print(cov_matrix_filtered)
```

### Covariance Matrix Heatmap

```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)  # for melt function

# Define the numeric and categorical variables
numeric_vars <- c("battery_power","clock_speed", "fc", "int_memory", "m_dep", "mobile_wt", "n_cores","pc", "px_height", "px_width", "ram", "sc_h", "sc_w", "talk_time")
categorical_vars <- c("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi", "price_range")

# Convert categorical variables to factors for the filtered dataset
filtered_mobileTrain <- filtered_mobileTrain %>%
  mutate_at(vars(all_of(categorical_vars)), as.factor)


# Calculate the covariance matrix for numeric variables
cov_matrix <- cov(filtered_mobileTrain[, numeric_vars])

# Create a heatmap of the covariance matrix
heatmap_data <- as.data.frame(as.table(cov_matrix))
colnames(heatmap_data) <- c("Variable_1", "Variable_2", "Covariance")  # Replace spaces with underscores

# Create the heatmap with covariance values as labels
ggplot(heatmap_data, aes(x = Variable_1, y = Variable_2, fill = Covariance)) +
  geom_tile() +
  geom_text(aes(label = round(Covariance, 2)), vjust = 0.5, size = 3) +  # Add covariance values as labels
  scale_fill_gradient2(low = "white", mid = "blue", high = "yellow", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Covariance Heatmap for Numeric Variables")
```

### Covariance Scatter Sub-Plots

```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)

# Calculate the covariance matrix for numeric variables
cov_matrix <- cov(filtered_mobileTrain[, numeric_vars])

# Create melted data for scatter sub-plots
heatmap_data <- as.data.frame(as.table(cov_matrix))
colnames(heatmap_data) <- c("Variable_1", "Variable_2", "Covariance")
melted_data <- melt(heatmap_data, id.vars = c("Variable_1", "Variable_2"))

# Sort the melted data by Covariance in descending order
sorted_melted_data <- melted_data %>%
  arrange(desc(value))  # Sort by 'value' instead of 'Covariance'

# Get the top X and bottom X rows
top_5 <- head(sorted_melted_data, 10)
bottom_5 <- tail(sorted_melted_data, 10)

# Create scatter sub-plots for the top X covariance values using ggplot2
top_plots <- ggplot(data = top_5, aes(x = Variable_1, y = Variable_2)) +
  geom_point(aes(size = value, color = value)) +
  labs(title = "Top 10 Covariance Scatter Plots") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  

# Create scatter sub-plots for the bottom X covariance values using ggplot2
bottom_plots <- ggplot(data = bottom_5, aes(x = Variable_1, y = Variable_2)) +
  geom_point(aes(size = value, color = value)) +
  labs(title = "Bottom 10 Covariance Scatter Plots") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  

# Display the scatter sub-plots
print(top_plots)
print(bottom_plots)
```

```         
```

### Binary Variables in relation to Price Range (Target Variable)

```{r}
# Counts and Contingency Tables for Binary Variables

# Bluetooth variable
blue_table <- table(filtered_mobileTrain$blue, filtered_mobileTrain$price_range)
row.names(blue_table) <- c("Has Bluetooth", "No Bluetooth")
blue_table

# Dual Sim
dual_sim_table <- table(filtered_mobileTrain$dual_sim, filtered_mobileTrain$price_range)
row.names(dual_sim_table) <- c("Has Dual Sim", "No Dual Sim")
dual_sim_table

# 4G 
fourG_table <- table(filtered_mobileTrain$four_g, filtered_mobileTrain$price_range)
row.names(fourG_table) <- c("Has 4G", "No 4G")
fourG_table

#3G
threeG_table <- table(filtered_mobileTrain$three_g, filtered_mobileTrain$price_range)
row.names(threeG_table) <- c("Has 3G", "No 3G")
threeG_table

# Touch Screen
touchscreen_table <- table(filtered_mobileTrain$touch_screen, filtered_mobileTrain$price_range)
row.names(touchscreen_table) <- c("Has Touch Screen", "No Touch Screen")
touchscreen_table

# Wifi
wifi_table <- table(filtered_mobileTrain$wifi, filtered_mobileTrain$price_range)
row.names(wifi_table) <- c("Has Wifi Capability", "No Wifi Capability")
wifi_table
```

```{r}
# Bar graphs with price range overlay for each binary variable

# Overlay Bargraphs

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = blue)) + ggtitle("Price Range with Bluetooth Overlay")

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = dual_sim)) + ggtitle("Price Range with Dual Sim Overlay")

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = four_g)) + ggtitle("Price Range with 4G Overlay")

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = three_g)) + ggtitle("Price Range with 3G Overlay")

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = touch_screen)) + ggtitle("Price Range with Touch Screen Overlay")

ggplot(filtered_factored_mobileTrain, aes(price_range)) + geom_bar(aes(fill = wifi)) + ggtitle("Price Range with Wifi Overlay")
```

### Chi-Squared Test on Binary Variables against Target variable

```{r}
# Load necessary libraries
library(dplyr)
library(kableExtra)
library(htmltools)

# Create a data frame to store chi-squared test results
chi_squared_results_df <- data.frame(variable = character(0), statistic = numeric(0), p_value = numeric(0))

# Create contingency tables and perform chi-squared tests for each categorical predictor
categorical_vars <- c("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi")
for (var in categorical_vars) {
  contingency_table <- table(filtered_mobileTrain$price_range, filtered_mobileTrain[[var]])
  chi_squared_result <- chisq.test(contingency_table)
  
  # Append results to the data frame
  chi_squared_results_df <- rbind(chi_squared_results_df, data.frame(variable = var, statistic = chi_squared_result$statistic, p_value = chi_squared_result$p.value))
}

# Print results in a formatted table
kable(chi_squared_results_df, format = "html", caption = "Chi-Squared Test Results") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))%>%
  column_spec(1:4, color = "black") %>%
  row_spec(0, color = "black")
```

### Feature Selection

Explanation (p-value, covariance, similar variables, business rules, etc.)

4G, touch screen, wifi = domain knowledge/business rules

RAM, battery_power = correlation w/ target variable

px_width, sc_w = covariance is very similar to heights, no loss with those variables, simultaneously more correlated to price (px_width is also normally distributed)

pc = highest correlation with fc, normally distributed, simultaneously higher correlation to price, no loss in fc (same function in mobile phone)

talk_time, mobile_wt, internal_memory = normally distributed variables, low correlations across variables (as phone gets lighter, phone gets more expensive)

REMOVE blue, dual_sim, three_g, fc, n_cores, px_height, sc_h, clock_speed, m_dep

```{r}
# Remove variables that will not be used in model

final_mobileTrain = subset(filtered_mobileTrain, select = -c(blue, dual_sim, three_g, fc, n_cores, px_height, sc_h, clock_speed, m_dep) )

```

### Hypothesis

Ho - Null hypothesis, there is no relationship between predictor variables in final_mobileTrain and target variable, price_range

Ha - Alternative hypothesis, contradicts null, there is a statistically significant relationship between the target variables

"model results reject \_\_\_ hypothesis in favor of \_\_\_ hypothesis"

### Baseline Model (Biggest Category Model "Data Science Using Python and R")

```{r}
#Find totals of each possible price range outcome in final training set
sum(final_mobileTrain$price_range == "0")

sum(final_mobileTrain$price_range == "1")

sum(final_mobileTrain$price_range == "2")

sum(final_mobileTrain$price_range == "3")
```

```{r}
#Find total records in final training set
dim(final_mobileTrain)
```

```{r}
#Divide counts by total records for percentages
(496/1988)*100

(497/1988)*100

(497/1988)*100

(498/1988)*100

#Baseline model assigns all records to biggest category percentage
```

Baseline model has an accuracy of 25.05%.

## C5.0 Decision Tree Model

```{r}
# Partition the Data Set

# Set Seed
set.seed(7)

n <- dim(final_mobileTrain)[1]

#Random Number Generator
train_ind <- runif(n) < 0.75

#Create Training and Test Data Sets
MobileTraining <- final_mobileTrain[ train_ind, ]
MobileTesting <- final_mobileTrain[ !train_ind, ]

```

```{r}
# Classification Model with Training Set
# C5.0 Model for multiple variables to predict price range

#Load Libraries
library(C50)

#Factor Price Range Variable
MobileTraining$price_range <- as.factor(MobileTraining$price_range)

#Run model algorithm on final_mobileTrain
C5_train <- C5.0(formula = price_range ~ battery_power + four_g + int_memory + mobile_wt + pc + px_width + ram + sc_w + talk_time + touch_screen + wifi, data = MobileTraining, control = C5.0Control(minCases = 65))

#Plot model
plot(C5_train)
```

```{r}
# Create data frame to predict
X = data.frame(battery_power = MobileTraining$battery_power, four_g = MobileTraining$four_g, int_memory = MobileTraining$int_memory, mobile_wt = MobileTraining$mobile_wt, pc = MobileTraining$pc, px_width = MobileTraining$px_width, ram = MobileTraining$ram, sc_w = MobileTraining$sc_w, talk_time = MobileTraining$talk_time, touch_screen = MobileTraining$touch_screen, wifi = MobileTraining$wifi)

#Classifications for each record
y_pred_train <- predict(object = C5_train, newdata = X)
head(y_pred_train, 10)
```

```{r}
# Subset predictor from test data set
X_test = data.frame(battery_power = MobileTesting$battery_power, four_g = MobileTesting$four_g, int_memory = MobileTesting$int_memory, mobile_wt = MobileTesting$mobile_wt, pc = MobileTesting$pc, px_width = MobileTesting$px_width, ram = MobileTesting$ram, sc_w = MobileTesting$sc_w, talk_time = MobileTesting$talk_time, touch_screen = MobileTesting$touch_screen, wifi = MobileTesting$wifi)

#Run test data through training model
ypred_test <- predict(object = C5_train, newdata = X_test)
head(ypred_test, 10)
```

```{r}
# Confusion matrix
C5_conf_matrix <- table(Actual = MobileTesting$price_range, Predicted = ypred_test)
print(C5_conf_matrix)

# Compute accuracy
C5_accuracy <- round(sum(diag(C5_conf_matrix)) / sum(C5_conf_matrix),4)
cat("C5.0 Accuracy:", C5_accuracy, "\n")
```

```         
```

```{r}
# Evaluation Metrics on Model
t1 <- table(MobileTesting$price_range, ypred_test)
row.names(t1) <- c("Actual: 0", "Actual: 1", "Actual: 2", "Actual: 3")
colnames(t1) <- c("Predicted: 0", "Predicted 1", "Predicted: 2", "Predicted: 3")
t1 <- addmargins(A = t1, FUN = list(Total = sum), quiet = TRUE)
t1
```

```{r}
# Load Libraries
library(C50)

# Confusion matrix for C5.0
C5_conf_matrix <- table(Actual = MobileTesting$price_range, Predicted = ypred_test)

# Calculate Metrics for C5.0
C5_accuracy <- round(sum(diag(C5_conf_matrix)) / sum(C5_conf_matrix), 4)
C5_error_rate <- round(1 - C5_accuracy, 4)

C5_sensitivity <- round(C5_conf_matrix[1, 1] / sum(C5_conf_matrix[1, ]), 4)
C5_specificity <- round(C5_conf_matrix[2, 2] / sum(C5_conf_matrix[2, ]), 4)
C5_precision <- round(C5_conf_matrix[1, 1] / sum(C5_conf_matrix[, 1]), 4)
C5_recall <- C5_sensitivity
C5_f1 <- round(2 * (C5_precision * C5_recall) / (C5_precision + C5_recall), 4)

# Print Metrics for C5.0
cat("C5.0 Accuracy:", C5_accuracy, "\n")
cat("C5.0 Error Rate:", C5_error_rate, "\n")
cat("C5.0 Sensitivity:", C5_sensitivity, "\n")
cat("C5.0 Specificity:", C5_specificity, "\n")
cat("C5.0 Precision:", C5_precision, "\n")
cat("C5.0 Recall:", C5_recall, "\n")
cat("C5.0 F1:", C5_f1, "\n")

```

```{r}
# suppressMessages()
suppressMessages({
  
# Load Libraries
library(C50)
library(caret)

# Set Seed for Reproducibility
set.seed(7)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a data frame to store the results
results <- data.frame(Actual = factor(), Predicted = factor())

# Perform k-fold cross-validation
folds <- createFolds(MobileTraining$price_range, k = num_folds)
for (fold in seq_along(folds)) {
  train_indices <- unlist(folds[-fold])
  test_indices <- folds[[fold]]
  
  fold_train <- MobileTraining[train_indices, ]
  fold_test <- MobileTraining[test_indices, ]
  
  # Run model algorithm on the training fold
  C5_train <- C5.0(formula = price_range ~ battery_power + four_g + int_memory + mobile_wt + pc + px_width + ram + sc_w + talk_time + touch_screen + wifi,
                   data = fold_train, control = C5.0Control(minCases = 65))
  
  # Create data frame to predict for training fold
  X = fold_train[, c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen", "wifi")]
  
  # Classifications for each record in training fold
  y_pred_train <- predict(object = C5_train, newdata = X)
  
  # Store predicted and actual labels for training fold
  fold_results_train <- data.frame(Actual = fold_train$price_range, Predicted = y_pred_train)
  
  # Subset predictor from test fold
  X_test = fold_test[, c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen", "wifi")]
  
  # Predictions on the test fold using the training model
  ypred_test <- predict(object = C5_train, newdata = X_test)
  
  # Store predicted and actual labels for test fold
  fold_results_test <- data.frame(Actual = fold_test$price_range, Predicted = ypred_test)
  
  # Combine results for both folds
  fold_results <- rbind(fold_results_train, fold_results_test)
  results <- rbind(results, fold_results)
}

# Calculate accuracy (you can use other performance metrics as needed)
accuracy <- round(sum(results$Predicted == results$Actual) / nrow(results),4)
cat("C5.0 Cross-Validation Accuracy:", accuracy, "\n")
})
```

```{r}
# suppressMessages()
suppressMessages({
  
library(pROC)

# Get number of observations in test set
n <- nrow(MobileTesting)

# Calculate AUC for each class
auc_C50_list <- list()
for (i in levels(MobileTesting$price_range)) {
  # Create vectors of the same length
  response_C50 <- as.numeric(MobileTesting$price_range == i)
  predictor_C50<- as.numeric(ypred_test)[1:nrow(MobileTesting)]

  # Calculate AUC
  roc_obj <- roc(response, predictor, levels = c(0, 1))
  auc_C50_list[[i]] <- auc(roc_obj)
}

# Calculate average AUC
auc_C50 <- round(mean(unlist(auc_list)),4)

# Print AUC
cat("Multi-class AUC for C5.0:", auc_C50, "\n")
})
```

### Support Vector Machines (SVM) Model

```{r}
# Load Libraries
library(e1071)

# Set Seed for Reproducibility
set.seed(7)

# Shuffle the Data
shuffled_data <- final_mobileTrain[sample(nrow(final_mobileTrain)), ]

# Calculate Training Set Size
train_ratio <- 0.75
train_size <- floor(nrow(shuffled_data) * train_ratio)

# Create Training and Test Data Sets
MobileTrainingSVM <- shuffled_data[1:train_size, ]
MobileTestingSVM <- shuffled_data[(train_size + 1):nrow(shuffled_data), ]

# Convert the target variable to a numeric format
MobileTrainingSVM$price_range <- as.numeric(MobileTrainingSVM$price_range) - 1

# Specify Predictor Variables
predictors <- c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen","wifi")

# Train the SVM model using the svm() function from the e1071 package
SVM_model <- svm(price_range ~ .,
                 data = MobileTrainingSVM[, c("price_range", predictors)],  # Include price_range and predictor columns
                 type = "C-classification",
                 kernel = "radial",
                 cost = 1)

# Convert the test target variable
MobileTestingSVM$price_range <- as.numeric(MobileTestingSVM$price_range) - 1

# Predictions on the test set
ypred_svm <- predict(SVM_model, newdata = MobileTestingSVM[, c("price_range", predictors)])  # Include price_range and predictor columns

```

```{r}
# Confusion matrix
conf_matrixSVM <- table(Actual = MobileTestingSVM$price_range, Predicted = ypred_svm)
print(conf_matrixSVM)

# Compute accuracy
accuracySVM <- round(sum(diag(conf_matrixSVM)) / sum(conf_matrixSVM),4)
cat("SVM Accuracy:", accuracySVM, "\n")

```

```{r}
# Load Libraries
library(e1071)

# Predictions on the test set
ypred_svm <- predict(SVM_model, newdata = MobileTestingSVM[, c("price_range", predictors)])

# Convert to factor for pROC
MobileTestingSVM$price_range <- as.factor(MobileTestingSVM$price_range)
ypred_svm_factor <- as.factor(ypred_svm)

# Check levels of class labels and predicted values
if (!identical(levels(MobileTestingSVM$price_range), levels(ypred_svm_factor))) {
  stop("Class label levels do not match with predicted value levels.")
}

# Calculate Metrics
conf_matrix <- table(Actual = MobileTestingSVM$price_range, Predicted = ypred_svm)

accuracy <- round(sum(diag(conf_matrix)) / sum(conf_matrix), 4)
error_rate <- round(1 - accuracy, 4)

sensitivity <- round(conf_matrix[1, 1] / sum(conf_matrix[1, ]), 4)
specificity <- round(conf_matrix[2, 2] / sum(conf_matrix[2, ]), 4)
precision <- round(conf_matrix[1, 1] / sum(conf_matrix[, 1]), 4)
recall <- sensitivity
f1 <- round(2 * (precision * recall) / (precision + recall), 4)

# Print Metrics
cat("Accuracy:", accuracy, "\n")
cat("Error Rate:", error_rate, "\n")
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1:", f1, "\n")

```

```{r}
# Load Libraries
library(e1071)
library(caret)

# Set Seed for Reproducibility
set.seed(7)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a data frame to store the results
results <- data.frame(Actual = integer(0), Predicted = integer(0))

# Perform k-fold cross-validation
folds <- createFolds(shuffled_data$price_range, k = num_folds)
for (fold in seq_along(folds)) {
  train_indices <- unlist(folds[-fold])
  test_indices <- folds[[fold]]
  
  fold_train <- shuffled_data[train_indices, ]
  fold_test <- shuffled_data[test_indices, ]
  
  # Convert the target variable to a factor format
  fold_train$price_range <- as.factor(fold_train$price_range)
  fold_test$price_range <- as.factor(fold_test$price_range)
  
  # Train the SVM model using the svm() function from the e1071 package
  SVM_model <- svm(price_range ~ .,
                   data = fold_train[, c("price_range", predictors)],
                   type = "C-classification",
                   kernel = "radial",
                   cost = 1)
  
  # Predictions on the test set for this fold
  ypred_svm <- predict(SVM_model, newdata = fold_test[, c("price_range", predictors)])
  
  # Store predicted and actual labels
  fold_results <- data.frame(Actual = fold_test$price_range, Predicted = ypred_svm)
  results <- rbind(results, fold_results)
}

# Calculate accuracy (you can use other performance metrics as needed)
accuracy <- round(sum(results$Predicted == results$Actual) / nrow(results),4)
cat("SVM Cross-Validation Accuracy:", accuracy, "\n")

```

```{r}
# suppressMessages()
suppressMessages({
  
library(pROC)

# Calculate multi-class AUC
auc_list_SVM <- list()
for (i in levels(MobileTestingSVM$price_range)) {
  # Create vectors of the same length
  response <- as.numeric(MobileTestingSVM$price_range == i)
  predictor <- as.numeric(ypred_svm)[1:nrow(MobileTestingSVM)]

  # Calculate AUC
  roc_obj_SVM <- roc(response, predictor, levels = c(0, 1))
  auc_list_SVM[[i]] <- auc(roc_obj_SVM)
}

# Calculate average AUC
auc_SVM <- round(mean(unlist(auc_list_SVM)),4)

# Print AUC
cat("Multi-class AUC for SVM:", auc_SVM, "\n")
})
```

### K-Nearest Neighbors (KNN) Model

```{r}
# Load Libraries
library(class)

# Set Seed for Reproducibility
set.seed(7)

# Shuffle the Data
shuffled_data <- final_mobileTrain[sample(nrow(final_mobileTrain)), ]

# Calculate Training Set Size
train_ratio <- 0.75
train_size <- floor(nrow(shuffled_data) * train_ratio)

# Create Training and Test Data Sets
MobileTrainingKNN <- shuffled_data[1:train_size, ]
MobileTestingKNN <- shuffled_data[(train_size + 1):nrow(shuffled_data), ]

# Convert the target variable to a numeric format
MobileTrainingKNN$price_range <- as.numeric(MobileTrainingKNN$price_range) - 1

# Specify Predictor Variables
predictors <- c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen", "wifi")

# Train the K-NN model using the knn() function from the class package
KNN_model <- knn(train = MobileTrainingKNN[, predictors],
                 test = MobileTestingKNN[, predictors],
                 cl = MobileTrainingKNN$price_range,
                 k = 8)  # You can adjust the value of k as needed

# Convert the test target variable
MobileTestingKNN$price_range <- as.numeric(MobileTestingKNN$price_range) - 1

# Predictions on the test set
ypred_knn <- as.numeric(KNN_model)

```

```{r}
# Confusion matrix
conf_matrixKNN <- table(Actual = MobileTestingKNN$price_range, Predicted = ypred_knn)
print(conf_matrixKNN)

# Compute accuracy
accuracyKNN <- round(sum(diag(conf_matrixKNN)) / sum(conf_matrixKNN),4)
cat("KNN Accuracy:", accuracyKNN, "\n")
```

```{r}
# Confusion matrix for K-NN
conf_matrixKNN <- table(Actual = MobileTestingKNN$price_range, Predicted = ypred_knn)

# Calculate Metrics for K-NN
accuracyKNN <- round(sum(diag(conf_matrixKNN)) / sum(conf_matrixKNN), 4)
error_rateKNN <- round(1 - accuracyKNN, 4)

sensitivityKNN <- round(conf_matrixKNN[1, 1] / sum(conf_matrixKNN[1, ]), 4)
specificityKNN <- round(conf_matrixKNN[2, 2] / sum(conf_matrixKNN[2, ]), 4)
precisionKNN <- round(conf_matrixKNN[1, 1] / sum(conf_matrixKNN[, 1]), 4)
recallKNN <- sensitivityKNN
f1KNN <- round(2 * (precisionKNN * recallKNN) / (precisionKNN + recallKNN), 4)

# Print Metrics for K-NN
cat("K-NN Accuracy:", accuracyKNN, "\n")
cat("K-NN Error Rate:", error_rateKNN, "\n")
cat("K-NN Sensitivity:", sensitivityKNN, "\n")
cat("K-NN Specificity:", specificityKNN, "\n")
cat("K-NN Precision:", precisionKNN, "\n")
cat("K-NN Recall:", recallKNN, "\n")
cat("K-NN F1:", f1KNN, "\n")

```

```{r}
# suppressMessages()
suppressMessages({
  
# Load Libraries
library(class)
library(caret)

# Set Seed for Reproducibility
set.seed(7)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a data frame to store the results
results <- data.frame(Actual = integer(0), Predicted = integer(0))

# Perform k-fold cross-validation
folds <- createFolds(shuffled_data$price_range, k = num_folds)
for (fold in seq_along(folds)) {
  train_indices <- unlist(folds[-fold])
  test_indices <- folds[[fold]]
  
  fold_train <- shuffled_data[train_indices, ]
  fold_test <- shuffled_data[test_indices, ]
  
  # Convert the target variable to a numeric format
  fold_train$price_range <- as.numeric(fold_train$price_range) - 1
  fold_test$price_range <- as.numeric(fold_test$price_range) - 1
  
  # Train the K-NN model using the knn() function from the class package
  KNN_model <- knn(train = fold_train[, predictors],
                   test = fold_test[, predictors],
                   cl = fold_train$price_range,
                   k = 5)  # You can adjust the value of k as needed
  
  # Predictions on the test set for this fold
  ypred_knn <- as.numeric(KNN_model)
  
  # Store predicted and actual labels
  fold_results <- data.frame(Actual = fold_test$price_range, Predicted = ypred_knn)
  results <- rbind(results, fold_results)
}

# Calculate accuracy (you can use other performance metrics as needed)
accuracy <- round(sum(results$Predicted == results$Actual) / nrow(results),4)
cat("KNN Cross-Validation Accuracy:", accuracy, "\n")
})
```

```{r}
# suppressMessages()
suppressMessages({
  
library(pROC)

# Calculate multi-class AUC
auc_list_KNN <- list()
for (i in levels(fold_test$price_range)) {
  # Create vectors of the same length
  response <- as.numeric(fold_test$price_range == i)
  predictor <- as.numeric(ypred_knn)[1:nrow(fold_test)]

  # Calculate AUC
  roc_obj_KNN <- roc(response, predictor, levels = c(0, 1))
  auc_list_KNN[[i]] <- auc(roc_obj_KNN)
}

# Calculate average AUC
auc_KNN <- round(mean(unlist(auc_list_KNN)),4)

# Print AUC
cat("Multi-class AUC for KNN:", auc_KNN, "\n")
})
```

### Logistic Regression Model

```{r}
# Load Libraries
library(dplyr)
library(nnet)

# Set Seed for Reproducibility
set.seed(7)

# Shuffle the Data
shuffled_data <- final_mobileTrain %>%
  sample_frac(1)

# Calculate Training Set Size
train_ratio <- 0.75
train_size <- floor(nrow(shuffled_data) * train_ratio)

# Create Training and Test Data Sets
MobileTrainingLR <- shuffled_data %>%
  slice(1:train_size)
MobileTestingLR <- shuffled_data %>%
  slice((train_size + 1):nrow(shuffled_data))

# Convert the target variable to a numeric format
MobileTrainingLR$price_range <- as.numeric(MobileTrainingLR$price_range) - 1

# Specify Predictor Variables
predictors <- c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen", "wifi")

# Train the Multinomial Logistic Regression model using multinom
logreg_model <- multinom(factor(price_range) ~ .,
                         data = MobileTrainingLR[, c("price_range", predictors)])

# Convert the test target variable
MobileTestingLR$price_range <- as.numeric(MobileTestingLR$price_range) - 1

# Predictions on the test set
ypred_logreg <- predict(logreg_model, newdata = MobileTestingLR[, c("price_range", predictors)], type = "probs")

# Convert probabilities to class labels
predicted_classes <- apply(ypred_logreg, 1, which.max)

```

```{r}
# Predictions on the test set
ypred_probs <- predict(logreg_model, newdata = MobileTestingLR[, c(predictors)], type = "probs")

# Convert probabilities to class labels
predicted_classes <- apply(ypred_probs, 1, which.max)

# Confusion matrix
conf_matrix_LR <- table(Actual = MobileTestingLR$price_range, Predicted = predicted_classes)
print(conf_matrix_LR)

# Compute accuracy
accuracy_LR <- round(sum(diag(conf_matrix_LR)) / sum(conf_matrix_LR), 4)
cat("Logistic Regression Accuracy:", accuracy_LR, "\n")

```

```{r}
# Predictions on the test set
ypred_probs <- predict(logreg_model, newdata = MobileTestingLR[, c(predictors)], type = "probs")

# Convert probabilities to class labels
predicted_classes <- apply(ypred_probs, 1, which.max)

# Confusion matrix for Logistic Regression
conf_matrix_LR <- table(Actual = MobileTestingLR$price_range, Predicted = predicted_classes)

# Calculate Metrics for Logistic Regression
accuracy_LR <- round(sum(diag(conf_matrix_LR)) / sum(conf_matrix_LR), 4)
error_rate_LR <- round(1 - accuracy_LR, 4)

sensitivity_LR <- round(conf_matrix_LR[1, 1] / sum(conf_matrix_LR[1, ]), 4)
specificity_LR <- round(conf_matrix_LR[2, 2] / sum(conf_matrix_LR[2, ]), 4)
precision_LR <- round(conf_matrix_LR[1, 1] / sum(conf_matrix_LR[, 1]), 4)
recall_LR <- sensitivity_LR
f1_LR <- round(2 * (precision_LR * recall_LR) / (precision_LR + recall_LR), 4)

# Print Metrics for Logistic Regression
cat("Logistic Regression Accuracy:", accuracy_LR, "\n")
cat("Logistic Regression Error Rate:", error_rate_LR, "\n")
cat("Logistic Regression Sensitivity:", sensitivity_LR, "\n")
cat("Logistic Regression Specificity:", specificity_LR, "\n")
cat("Logistic Regression Precision:", precision_LR, "\n")
cat("Logistic Regression Recall:", recall_LR, "\n")
cat("Logistic Regression F1:", f1_LR, "\n")

```

```{r}
# Load Libraries
library(dplyr)
library(nnet)
library(caret)

# Set Seed for Reproducibility
set.seed(7)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a data frame to store the results
results <- data.frame(Actual = integer(0), Predicted = integer(0))

# Perform k-fold cross-validation
folds <- createFolds(shuffled_data$price_range, k = num_folds)
for (fold in seq_along(folds)) {
  train_indices <- unlist(folds[-fold])
  test_indices <- folds[[fold]]
  
  fold_train <- shuffled_data[train_indices, ]
  fold_test <- shuffled_data[test_indices, ]
  
  # Convert the target variable to a factor format
  fold_train$price_range <- as.factor(fold_train$price_range)
  fold_test$price_range <- as.factor(fold_test$price_range)
  
  # Train the Multinomial Logistic Regression model using multinom
  logreg_model <- multinom(factor(price_range) ~ .,
                           data = fold_train[, c("price_range", predictors)])
  
  # Predictions on the test set for this fold
  ypred_logreg <- predict(logreg_model, newdata = fold_test[, c("price_range", predictors)], type = "probs")
  
  # Convert probabilities to class labels
  predicted_classes <- apply(ypred_logreg, 1, which.max)
  
  # Store predicted and actual labels
  fold_results <- data.frame(Actual = fold_test$price_range, Predicted = predicted_classes)
  results <- rbind(results, fold_results)
}

# Calculate accuracy (you can use other performance metrics as needed)
accuracy <- round(sum(results$Predicted == results$Actual) / nrow(results),4)
cat("Logistic Regression Cross-Validation Accuracy:", accuracy, "\n")

```

```{r}

```

### Naive Bayes Model

```{r}
# Load Libraries
library(e1071)

# Set Seed for Reproducibility
set.seed(7)

# Shuffle the Data
shuffled_data <- final_mobileTrain[sample(nrow(final_mobileTrain)), ]

# Calculate Training Set Size
train_ratio <- 0.75
train_size <- floor(nrow(shuffled_data) * train_ratio)

# Create Training and Test Data Sets
MobileTrainingNB <- shuffled_data[1:train_size, ]
MobileTestingNB <- shuffled_data[(train_size + 1):nrow(shuffled_data), ]

# Convert the target variable to a numeric format
MobileTrainingNB$price_range <- as.numeric(MobileTrainingNB$price_range) - 1

# Specify Predictor Variables
predictors <- c("battery_power", "four_g", "int_memory", "mobile_wt", "pc", "px_width", "ram", "sc_w", "talk_time", "touch_screen", "wifi")

# Train the Naive Bayes model
NB_model <- naiveBayes(price_range ~ .,
                       data = MobileTrainingNB[, c("price_range", predictors)],  # Include price_range and predictor columns
                       laplace = 1)  

# Convert the test target variable
MobileTestingNB$price_range <- as.numeric(MobileTestingNB$price_range) - 1

# Predictions on the test set
ypred_nb <- predict(NB_model, newdata = MobileTestingNB[, c("price_range", predictors)])  # Include price_range and predictor columns
```

```{r}
# Confusion matrix
conf_matrix_NB <- table(Actual = MobileTestingNB$price_range, Predicted = ypred_nb)
print(conf_matrix_NB)

# Compute accuracy
accuracy_NB <- round(sum(diag(conf_matrix_NB)) / sum(conf_matrix_NB),4)
cat("Naive Bayes Accuracy:", accuracy_NB, "\n")
```

```{r}
# Confusion matrix for Naive Bayes
conf_matrix_NB <- table(Actual = MobileTestingNB$price_range, Predicted = ypred_nb)

# Calculate Metrics for Naive Bayes
accuracy_NB <- round(sum(diag(conf_matrix_NB)) / sum(conf_matrix_NB), 4)
error_rate_NB <- round(1 - accuracy_NB, 4)

sensitivity_NB <- round(conf_matrix_NB[1, 1] / sum(conf_matrix_NB[1, ]), 4)
specificity_NB <- round(conf_matrix_NB[2, 2] / sum(conf_matrix_NB[2, ]), 4)
precision_NB <- round(conf_matrix_NB[1, 1] / sum(conf_matrix_NB[, 1]), 4)
recall_NB <- sensitivity_NB
f1_NB <- round(2 * (precision_NB * recall_NB) / (precision_NB + recall_NB), 4)

# Print Metrics for Naive Bayes
cat("Naive Bayes Accuracy:", accuracy_NB, "\n")
cat("Naive Bayes Error Rate:", error_rate_NB, "\n")
cat("Naive Bayes Sensitivity:", sensitivity_NB, "\n")
cat("Naive Bayes Specificity:", specificity_NB, "\n")
cat("Naive Bayes Precision:", precision_NB, "\n")
cat("Naive Bayes Recall:", recall_NB, "\n")
cat("Naive Bayes F1:", f1_NB, "\n")

```

```{r}
# Load Libraries
library(e1071)
library(caret)

# Set Seed for Reproducibility
set.seed(7)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a data frame to store the results
results <- data.frame(Actual = integer(0), Predicted = integer(0))

# Perform k-fold cross-validation
folds <- createFolds(shuffled_data$price_range, k = num_folds)
for (fold in seq_along(folds)) {
  train_indices <- unlist(folds[-fold])
  test_indices <- folds[[fold]]
  
  fold_train <- shuffled_data[train_indices, ]
  fold_test <- shuffled_data[test_indices, ]
  
  # Convert the target variable to a factor format
  fold_train$price_range <- as.factor(fold_train$price_range)
  fold_test$price_range <- as.factor(fold_test$price_range)
  
  # Train the Naive Bayes model
  NB_model <- naiveBayes(price_range ~ .,
                         data = fold_train[, c("price_range", predictors)],
                         laplace = 1)
  
  # Predictions on the test set for this fold
  ypred_nb <- predict(NB_model, newdata = fold_test[, c("price_range", predictors)])
  
  # Store predicted and actual labels
  fold_results <- data.frame(Actual = fold_test$price_range, Predicted = ypred_nb)
  results <- rbind(results, fold_results)
}

# Calculate accuracy (you can use other performance metrics as needed)
accuracy <- round(sum(results$Predicted == results$Actual) / nrow(results),4)
cat("Naive Bayes Cross-Validation Accuracy:", accuracy, "\n")

```

```{r}

```
